\thusetup{
  %******************************
  % 注意：
  %   1. 配置里面不要出现空行
  %   2. 不需要的配置信息可以删除
  %******************************
  %
  %=====
  % 秘级
  %=====
  secretlevel={秘密},
  secretyear={10},
  %
  %=========
  % 中文信息
  %=========
  ctitle={基于屏上摄像头的手型识别与交互技术},
  cdegree={工学学士},
  cdepartment={计算机科学与技术系},
  cmajor={计算机科学与技术},
  cauthor={梁宸},
  csupervisor={史元春教授},
  cassosupervisor={喻纯副研究员}, % 副指导老师
  ccosupervisor={某某某教授}, % 联合指导老师
  % 日期自动使用当前时间，若需指定按如下方式修改：
  % cdate={超新星纪元},
  %
  % 博士后专有部分
  cfirstdiscipline={计算机科学与技术},
  cseconddiscipline={系统结构},
  postdoctordate={2009年7月——2011年7月},
  id={编号}, % 可以留空： id={},
  udc={UDC}, % 可以留空
  catalognumber={分类号}, % 可以留空
  %
  %=========
  % 英文信息
  %=========
  etitle={An Introduction to \LaTeX{} Thesis Template of Tsinghua University v\version},
  % 这块比较复杂，需要分情况讨论：
  % 1. 学术型硕士
  %    edegree：必须为Master of Arts或Master of Science（注意大小写）
  %             “哲学、文学、历史学、法学、教育学、艺术学门类，公共管理学科
  %              填写Master of Arts，其它填写Master of Science”
  %    emajor：“获得一级学科授权的学科填写一级学科名称，其它填写二级学科名称”
  % 2. 专业型硕士
  %    edegree：“填写专业学位英文名称全称”
  %    emajor：“工程硕士填写工程领域，其它专业学位不填写此项”
  % 3. 学术型博士
  %    edegree：Doctor of Philosophy（注意大小写）
  %    emajor：“获得一级学科授权的学科填写一级学科名称，其它填写二级学科名称”
  % 4. 专业型博士
  %    edegree：“填写专业学位英文名称全称”
  %    emajor：不填写此项
  edegree={Doctor of Engineering},
  emajor={Computer Science and Technology},
  eauthor={Xue Ruini},
  esupervisor={Professor Zheng Weimin},
  eassosupervisor={Chen Wenguang},
  % 日期自动生成，若需指定按如下方式修改：
  % edate={December, 2005}
  %
  % 关键词用“英文逗号”分割
  ckeywords={智能手机, 屏上摄像头, 手部感知, 全手型交互},
  ekeywords={smart phone, on-screen camera, hand sensing, full-hand interaction}
}

% 定义中英文摘要和关键字
\begin{cabstract}

随着信息技术的不断发展，智能手机已成为人们生活中必不可少的移动电子设备。目前，人们与智能手机的交互往往被限制在一块触摸屏幕上，这会给用户造成许多交互上的不便，如误触、操作繁琐、交互效率低等。另一方面，摄像头是普遍存在于智能手机上的硬件，且拥有十分强大的感知能力。因此，基于手机内置摄像头的传感方案具有巨大的交互感知潜力——通过简单的改造，对手部图像进行捕捉、识别，可以使智能手机拥有对于用户屏幕外手部行为的感知能力，进而实现更智能的交互。

我们提出了一种RGB（彩色）/IR（红外光）双模态的基于单目视觉的智能手机感知增强的方案，它充分地考虑了效率与感知信息收益的权衡。算法流程由MobileNetV2握姿分类模型、MobileNetV2-SSD指尖检测模型、基于曲率分布的IR指尖检测算法与运动模式检测算法四个步骤组成。我们的方案能够支持移动端实时的离线计算，并输出与手部交互密切相关的高层语义信息，如手势、指尖位置、指尖运动状态等信息。基于这些手部信息，我们设计了误触检测与免解锁检测两个实用的交互应用，并通过定量实验与用户实验对这两个应用进行评价。

本论文的主要贡献有以下三点：
\begin{enumerate}
    \item 提出了一套高效、适用性好的基于单目图像的智能手机手型感知的算法；
    \item 探索了手型感知技术在单目RGB与IR摄像头的硬件条件下的可能性，分别提出了更鲁棒、更高效的指尖识别解决方案；
    \item 提出了误触检测与免验证检测两个被动交互的设计，并通过定量实验分析与定性用户实验证明这两种被动交互设计的有效性与优越性。
\end{enumerate}

\end{cabstract}

% 如果习惯关键字跟在摘要文字后面，可以用直接命令来设置，如下：
% \ckeywords{\TeX, \LaTeX, CJK, 模板, 论文}

\begin{eabstract}

As information technology continuously develops, smart phone has become an indispensable mobile device in our daily life. The interaction between people and smart phones is largely confined to a capacitive touch screen, which causes many inconveniences, such as mistouch, tedious operation, low efficiency, etc. However, we may easily ignore that cameras are ubiquitous on smart phones, and they are natural sensors with strong sensing ability. Therefore, sensing technique based on the built-in camera of smart phone has great potential in supporting interaction. Through simple modification, built-in camera captures and recognizes user's hand image, enabling smart phone to perceive user's hand behavior beyond the screen, leading to more intelligent interaction.

We propose a RGB/IR dual-mode hand sensing solution based on monocular vision, balancing the trade-off between efficiency and information gain. Our algorithm pipeline consists of four elements: a MobileNetV2 gesture classification model, a MobileNetV2-SSD fingertip detection model, an IR fingertip detection algorithm based on curve distribution and a pattern detection algorithm. Our pipeline can support real-time offline computing on smart phones and output high-level semantic information contributed to hand interaction, such as gesture, fingertip position, fingertip motion status and so on. Based on these information, we designed two practical interaction applications: mistouch detection and authentication-free detection. Finally we evaluated these two applications through quantitative experiments and user experiments.

Specificly, our contribution are threefolds: 

\begin{enumerate}
    \item We develop an efficient monocular hand sensing pipeline on smart phone.
    \item We explore hand sensing solution under monocular RGB and IR cameras, and respectively propose a robust fingertip recognition algorithm.
    \item We design two novel interaction techniques - mistouch detection and authentication-free detection, and prove their superiority through quantitative analysis and user experiments.
\end{enumerate}

\end{eabstract}

% \ekeywords{\TeX, \LaTeX, CJK, template, thesis}
