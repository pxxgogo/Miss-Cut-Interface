Air+Touch: Interweaving Touch & In-Air Gestures

ABSTRACT

We present Air+Touch, a new class of interactions that interweave touch events with in-air gestures, offering a unified input modality with expressiveness greater than each input modality alone. We demonstrate how air and touch are highly complementary: touch is used to designate targets and segment in-air gestures, while in-air gestures add expressivity to touch events. For example, a user can draw a circle in the air and tap to trigger a context menu, do a finger 'high jump' between two touches to select a region of
text, or drag and in-air ‘pigtail’ to copy text to the clipboard. Through an observational study, we devised a basic taxonomy of Air+Touch interactions, based on whether the in-air component occurs before, between or after touches. To illustrate the potential of our approach, we built four applications that showcase seven exemplar Air+Touch interactions we created.

我们提出了Air+Touch，这是一种新的交互方式。它通过结合空中手势与触摸事件，提供一种统一的输入模式，其表现力大于每种单独的输入模态。我们展示了空中手势与触摸事件是如何高度互补的：触摸用于指定目标与切分空中手势，而空中手势则增加了触摸事件的表现力。例如，用户可以在空中绘制一个圆圈并点击以触发上下文菜单，在两次触摸之间进行一次“跳跃”以选择一个区域的
文本，或拖动和在空中画“猪尾巴形”来将文本复制到剪贴板。通过观察性研究，我们根据空中手势是在触摸之前，之间还是之后发生，将Air+Touch 交互进行分类。为了说明我们的方法的潜力，我们构建了四个应用程序，展示了我们构建的七种Air+Touch交互方式。

INTRODUCTION
A generation of mobile devices has relied on touch as the primary input modality. However, poking with a fingertip lacks immediate expressivity. In order to support richer actions, touch must be overloaded in time (e.g., long press), space (e.g., drawing an ‘s’ to silence the phone) or configuration (two-finger tap is ‘alt click’). These approaches suffer from one or more of the following issues: scalability of gesture set, time consuming to perform, “Midas” touch, and significant finger occlusion on small screens. Thus, there is an ongoing challenge to expand the envelope of touch interactions by combining it with new input dimensions that increases richness. Recently, devices such as the Samsung S4 smart phone [22] have emerged with hover sensing capability. In-air (or “free-space”) gesturing is an area of intense research (see e.g., [7, 17]). These interactions are attractive as they can utilize a space many times larger than a device’s physical boundaries, allowing for more comfortable and potentially richer interactions. However, in-air gestures are typically treated as a separate input modality, rather than integrated with existing touch-based techniques. Further, in-air gestures suffer from the challenge of segmentation: little literature has discussed how to systematically separate intentional gestures from accidental finger movements.

如今的移动设备依赖触摸作为主要输入模式。然而，指尖点击缺乏立即表达能力。为了支持更丰富的动作，触摸必须在时间（例如，长按）、空间（例如，绘制's'以使电话静音）或配置（双指点击是'alt click'）的维度进行扩展。这些方法面临以下一个或多个问题：手势集的可扩展性，执行的耗时，“Midas”触摸以及小屏幕上的显著手指遮挡。因此，通过将触摸交互与新的输入维度相结合，扩展触摸交互是一个持续的挑战。最近，诸如三星S4等智能手机[22]等设备已经具备悬停感应功能。空中（或“自由空间”）手势是一个深入研究的领域（参见例如[7,17]）。这些交互很有吸引力，因为它们可以利用比设备物理边界大许多倍的空间，从而实现更舒适且更有表现力的交互。然而，空中手势通常被视为单独的输入模态，而不是与现有的基于触摸的技术集成。此外，空中手势受到分割的挑战：很少有文献讨论过如何系统地区分有操作意图的手势与无意的手指运动。

In this paper, we reconsider touch and in-air gestures beyond their individual domains. We propose a synthesis of these two input modalities, achieving interaction richness and robustness that neither can provide alone. Indeed, we found in-air and touch inputs to be highly complementary: touch is used to designate targets and segment in-air gestures, while in-air gestures add expressivity and modality to touch events. This Air+Touch modality outlines a class of interactions that enable fluid use of a device’s screen and the space above it.

这篇论文中，我们重新考虑了触摸与空中手势，我们提出了一种综合上述两种输入模态的方法，使交互的语义丰富性与鲁棒性均高于单一模态。事实上，我们发现，空中手势和触摸操作是高度互补的：触摸用于指定目标与切分空中手势，而空中手势则增加了触摸事件的表现力。这样一种Air+Touch的模态刻画了一类允许用户在设备屏幕与其上方区域流畅操作的交互方式。

To explore this possibility, we start with a focus on the scenario of single-finger interaction, where a person uses his or her thumb or index finger to gesture in the air and also touch the screen. Through an observational study, we devised a simple taxonomy of Air+Touch interactions. We propose that in-air gestures can augment interactions before, between and after touch events. And in turn, touch events are used to segment in-air gestures and can also specify an on-screen target (e.g., a photo or map location). In-air gestures can be parameterized based on shape, velocity and/or time of a finger’s movement. Figure 1 offers three examples, from left to right: 1) circle-in-air and tap an icon to trigger a context menu, 2) do a finger 'high jump' between two taps to select a region of text, or 3) tap and cycle the finger in air to continuously zoom a map. 

为了探索它的可能性，我们首先关注一种单一手指交互的情形——用户使用他的食指或拇指进行空中手势或触摸屏幕。通过观察，我们给Air+Touch交互设计了一个简单的分类：通过在触摸事件的之前、之间、之后插入空中手势来增强交互。反之，触摸事件可用来切分空中手势以及选定目标。对于空中手势，可以通过形状、速度、运动时间进行参数化。图1提供了三个例子，从左到右分别是：(1)空中画圈后点击一个图标来处罚上下文菜单；(2)在两次触摸之间进行一次“跳跃”以选择一个区域内的文本；(3)点击后用手指在空中画圈可以持续放大地图。

RELATED WORK

Our work extends the input area from the touch screen to the space immediately above it, which is related to research that situates interactions beside, behind & above digital surfaces. For example, SideSight [3] uses infrared sensors to track finger movements from the sides of a mobile device. Magnetic sensors have also been used to enable similar interaction styles in Abracadabra [6] and MagiTact [14]. Wigdor et al. explore the design space of a two-sided interactive tabletop surface [25]. NanoTouch [2] and LucidTouch [24] demonstrated that the back surface of a device can be used to increase the interactive area.

我们的工作将输入区域从触摸屏扩展到其上方的空间，这与触摸屏表面的侧面，后方和上方的交互研究相关。例如，SideSight [3]使用红外传感器跟踪移动设备侧面的手指移动。磁性传感器也被用于在Abracadabra [6]和MagiTact [14]中以实现类似的交互；Wigdor等人探索双面交互式桌面的设计[25]；NanoTouch [2]和LucidTouch [24]证明了设备的背面可以用来扩展交互区域。

A number of research projects have focused on the space above interactive tabletops, such as Hilliges et al.’s Interactions in the Air [7], Marquardt et al.’s Continuous Interaction Space [17], and Banerjee et al.’s Pointerable [1]. In the realm of mobile devices, HoverFlow uses infrared sensors [16] and Niikura et al. use a high frame rate camera [18] to track hand/finger gestures above a mobile device. Marquardt et al. propose blending a digital surface and the space above it into a continuum wherein touch, gesture and tangibles can equally take place [17]. However, there is no discussion of mechanisms for segmenting in-air gestures (i.e., rejecting unintended finger movements). Further, the free-space and touch gestures generally co-exist, rather than being interwoven as we propose. 

许多研究项目都集中在交互屏幕上方的空间，例如Hilliges等人的“空中交互”[7]，Marquardt等人的“连续交互空间”[17]和Banerjee等人的研究项目[1]。在移动设备领域，HoverFlow使用红外传感器[1]，Niikura等人使用高帧率摄像头[18]跟踪移动设备上方的手/手势。Marquardt等人提出将数字表面及其上方的空间结合，使得触摸、手势和物体均可触发交互[17]。然而，还没有工作讨论过用于分割空中手势的机制（例如：检测非交互意图的手指运动）。进一步的，（这些工作）交互空间和触摸手势通常共存，而不是像我们提出的那样相互结合。

A natural next step is for researchers to explore in-air gestures in the space surrounding a device. Kratz et al. show that gestures above, beside and behind a mobile device yield better performance, compared to a virtual trackball, in manipulating 3D objects [15]. Jones et al. find that around-device free-space interaction can be as good as touch [13]. This work also defines ‘comfort zones’ around a device, which has strong implications for applying different sensor orientations. Samsung has shipped several basic in-air gestures with their Galaxy S4 [22]: A hand hovering on a lock screen shows time and notifications, and swiping left or right above a screen navigates a photo album. 

自然地，研究人员下一步要研究的是设备周围的环绕空间中的手势交互。 Kratz等人指出与虚拟轨迹球相比，通过手势进行设备的环绕操作（移动设备上方，旁边和后方）在操纵3D对象时会产生更好的性能[15]。琼斯等人发现设备周围的自由空间交互可以像触摸一样好[13]。这项工作还定义了设备周围的“舒适区”，这对不同方向的传感器的应用具有重要意义。三星在Galaxy S4上发布了几款基本的空中手势[22]：一只手在锁定屏幕上移动显示时间和通知，并在屏幕上方向左或向右滑动导航相册。 

Air+Touch also builds off of previous work that synthesized multiple inputs to create new interaction possibilities. Pen+Touch [11] synthesized pen and touch inputs to create new tools, such as using touch to hold a photo and pen to drag off and create a copy. Motion+Touch [10] combined touch with the motion sensing capability of a mobile device to yield touch-enhanced motion gestures and motionenhanced touch. Pen+Motion [9] combined pen input with pen motions, enabling new gestural input abilities. Our work synthesizes touch and in-air gesture in several new ways. First, we provide an input structure to segment in-air gesture using touch, and to augment touch using in-air gesture. Second, air and touch interleave each other, yielding a permutation of input sequences than can richly parameterize interactions. 

Air+Touch还基于以前的工作，这些工作综合了多种输入技术，实现新型交互的原型。 Pen + Touch [11]综合了笔和触摸输入形成一种新的输入模态，例如使用触摸来保持照片，使用笔拖动并创建副本。 Motion + Touch [10] 将触摸与运动感知结合，以产生触摸增强的动作手势和运动增强的触摸。Pen + Motion [9]将笔输入与笔的运动相结合，实现新的输入模态。我们的工作以几种新的方式综合了触摸和空中手势。首先，我们提供一种输入结构，使用触摸来分割空中手势，并使用空中手势来增强触摸。其次，空中手势和触摸相互交错，产生输入序列，给交互带来更多信息。

DESIGN FINDINGS FROM OBSERVATONAL STUDY

To ground and guide our initial exploration of Air+Touch interactions, we conducted a study to observe finger behavior above mobile screens when users are engaged in interactive tasks. We recruited 12 participants (5 female, ages 24-36). One participant was left-handed, one was ambidextrous, and all were regular smartphones users.  


为了指导和指导我们对Air+Touch交互的初步探索，我们进行了一项研究，以便在用户参与交互式任务时观察移动屏幕上方的手指行为。我们招募了12名参与者（5名女性，年龄24-36岁）。一名参与者是左撇子，一名是双手，所有人都是普通的智能手机用户。

We asked each participant to perform a set of common tasks on a smartphone (e.g., compose a text message, navigate on a map). We videotaped the sessions and looked for patterns in how fingers hovered or moved in the space immediately above the screen. From this, we distilled a set of features that could translate into gestural input, while avoiding collisions (i.e., reducing confusion) with natural finger movements. Next, we discuss how these features can contribute to the design of in-air gestures, and further, how touches can be used as natural delimiters to segment these actions.  

我们要求每个参与者在智能手机上执行一组常见任务（例如，撰写文本消息，在地图上导航）。我们对会话进行了录像，并寻找手指离开屏幕后的运动模式。由此，我们提炼出一组可以转化为手势输入的特征，同时避免与自然手指运动的碰撞（即减少混淆）。接下来，我们将讨论这些功能如何有助于空中手势的设计，以及如何将触摸用作自然分隔符来分割这些动作。

Air: Properties of Above-Screen Finger Movements 

Participants in our study exhibited a wide range of in-air, above-screen finger behaviors. This included hovering over the screen between touches, retracting to the bezels when the screen needed to be read, and wiggling fingers when uncertain about what to do (such as while searching for a button). When discussing the contents of the screen, people also used their fingers to point and wave at content, or to gesture as they spoke, similar to how hand gestures are used in conversation. In particular, we focused on three main categories of finger movement behavior 1) path – the trajectory of fingers’ movement, 2) position – fingers’ particular positions above the screen, and 3) repetition –how users repeat certain finger movement. 

实验的参与者展示了一系列空中、屏幕上方的手指行为。这包括触摸之间的悬空、当屏幕需要被读出时收回手指至边框、不确定做什么时扭动手指（例如在找某个按钮）。在讨论屏幕内容时，人们还会用他们的手指指向内容或在内容处挥动；或者在他们说话时做出手势，就像日常对话中那样。特别地，我们关注手指运动行为的三个主要类别：1）路径 - 手指运动的轨迹，2）位置 - 手指在屏幕上方的特定位置，以及3）重复 - 用户重复某些手指运动。

These observations informed Air+Touch design in two ways. Foremost, they illuminated the kinds of above-screen finger movements users can comfortably reproduce, which we then adopted as part of our vocabulary of in-air movements. Secondly, it allowed us to craft a vocabulary of gestures that can be easily disambiguated from natural finger movements. Below are some exemplar findings that later informed our design of Air+Touch gestures: 


这些观察结果以两种方式启发了Air + Touch设计。首先，这阐明了用户可以舒适地完成的屏幕上方的手指动作，我们将其作为我们的空中动作词汇集合的一部分。其次，它允许我们制作一个区别于自然手势的手势词汇表。以下是一些启示我们Air + Touch手势设计的手势示例：

Elliptical paths: Few of the finger motions we observed followed smooth, elliptical paths. This suggested that a circling action could be distinctive.

椭圆路径：我们观察到很少有手指运动遵循平滑的椭圆路径，这说明椭圆路径的环绕手势是可分辨的。

Rectangular paths: Similar to what Grossman et al. found in [5], few participants exhibited right angles in their finger trajectories. This suggested that paths with corners, such as an L-shaped gesture, could also be robustly recognized. 

矩形路径：与Grossman等人在[5]中的发现相似，很少参与者的手指轨迹中会出现直角。这表明带有棱角的路径，例如“L型”路径，可以被鲁棒地识别。

Leveraging height: Most users’ finger movements occurred close to the screen. This suggested that in-air gestures with atypical height components could be disambiguated from typical interactions.  

高度变化：大多数用户的手指移动发生在靠近屏幕的位置。这表明具有明显高度变化的空中姿势与普通的交互手势是可分辨的。

Using framing gestures: Whack Gestures [12] demonstrated that simple gestures (e.g., a whack) can yield expressive input when used as a framing feature (i.e., <frame_gesture> primary_gesture </frame_gesture>). Matched framing gestures can dramatically decrease the probability of false positives, even when the underlying gesture has a high error rate. In our study, we observed that users seldom touched the same location twice, except when scrolling, and in this case, rarely performed any finger movement of interest in the intervening time. This suggested that in-air gestures could be performed between framing touches. Another possibility is to include framing within the air gesture, such as using the first in-air circle as the signal that triggers recognition for subsequent finger circling (similar to using consective “whacks” in [12]). 


使用框架手势：Whack Gestures [12]证明，当用作框架特征（即<frame_gesture> primary_gesture </ frame_gesture>）时，简单的手势（例如，敲击）可以产生表达性输入。虽然底层的手势具有高错误率，但是匹配的框架手势可以显着降低误报的可能性。在我们的研究中，我们观察到用户很少两次触摸同一位置，除非滚动，并且在这种情况下，很少在中间时间执行任何待识别的手势。这表明可以在框架触摸之间执行空中手势。另一种可能性是在空中手势中包括框架，例如在空中画圈作为触发手指盘旋识别的信号（类似于[12]中使用连续性“击打”）。

Touch: Delimiting In-Air Gestures

Even with a carefully designed in-air gesture set, the uncertain nature of free space gestures demands a more explicit way to signal when an interaction is actually taking place. Our observations suggested that touch events could serve as a powerful and intuitive delimiter. In a typical interactive task, touch interleaves ‘air’ by bringing an in-air finger movement to a closure when the finger touches the screen or by introducing a new chunk of in-air
movement as the finger disengages itself from the screen. Thus touch naturally segments in-air gestures into three possible categories: before, between or after touches. This allows the in-air gesture recognition engine to search only a small window of time for applicable in-air finger move-
ments (i.e., instead of constant monitoring). In the remainder of the paper, these temporal categories serve as the organizing principle for the example Air+Touch interactions we created.

即使使用精心设计的空中手势集合，自由空间手势的不确定性也需要显式的交互起始与终止信号。观察表明触摸事件可以作为一个强大而直观的分隔符。在典型的交互任务中，触摸与空中手势通过触摸引出空中手势与触摸终止空中手势两种方式结合。因此，触摸自然地将空中手势分成三类：触摸之前，之间或之后。这允许空中手势识别引擎仅在空中手指移动窗口时间内搜索 （而不必不断监测）。在本文的其余部分，这些时间类别作为Air + Touch交互示例的分类标准。

Air+Touch: A Gesture Vocabulary

Our observations also helped us to craft an initial vocabulary of in-air gestures, which can be delimited by touch events in three ways as described in the previous section. To further explore this space, we looked at existing applications and considered whether any of the Air+Touch gestures could be adopted to enhance the present interaction. This helped us come up with four applications covering a set of seven Air+Touch gestures (Figure 2, in red) that are representative (but not inclusive) of the entire design space.


我们的观察也帮助我们创建了空中手势的初始词汇集合，如上节所述，可以通过三种方式触摸事件来界定。为了进一步探索其交互空间，我们观察了现有的应用程序，并考虑是否可以采用任何Air + Touch手势来增强当前的交互。这有助于我们提出四个应用程序，涵盖一组七个Air + Touch手势（图2，红色），这些手势是整个设计空间的代表（但不包括在内）。

Corner: the finger contains a 90-degree angle in air (on a plane perpendicular to the screen);
Circle: the finger draws smooth, cyclical paths in the air.
Pigtail: the finger draws a small loop along its in-air trajectory.
Zigzag: the finger makes sharp ‘turns’ in air (on a plane parallel to the screen), e.g., drawing an ‘L’ or ‘Z’; 
Spike: the finger reaches a ‘special’ air position during its movement, e.g., reaching a position higher than the usual hover range, or a position outside the screen boundary.

角手势：手指在空气中绘制90度角（在垂直于屏幕的平面上）;
圆手势：手指在空中绘制平滑的圆形路径。
猪尾手势：手指沿着空中轨迹绘制一个小环。
之型手势：手指在空气中（在与屏幕平行的平面上）产生剧烈的“转弯”，例如画出“L”或“Z”;
尖刺手势：手指在其移动期间到达空中特殊位置，例如，到达高于通常悬停范围的位置，或屏幕边界外的位置。

AIR+TOUCH PROTOTYPE

There are an increasing number of devices featuring capacitive touchscreens able to track fingers in the air (i.e., hover sensing). At CES 2014, Synaptics demonstrated a prototype touchpad able to track fingers at up to 4cm away [23]. All indications suggest this technology will continue to improve and become more pervasive. Unfortunately, the sensing range on today’s consumer devices is limited. For example, the Samsung Galaxy S4 has a tracking range of approximately 1.5cm.

越来越多的设备具有能够在空中跟踪手指的电容式触摸屏（例如，悬浮检测）。在2014年国际消费电子展上，Synaptics展示了一款原型触摸板，能够在距离最远4厘米处追踪手指[23]。所有迹象表明，这项技术将继续改进并变得更加普遍。不幸的是，当今消费类设备的感应范围有限。例如，三星Galaxy S4的跟踪范围约为1.5厘米。

Thus, in order to explore the full range of Air+Touch interactions that might be possible in a few years, it was necessary to build our own prototype. Although bulky today, our prototype served as a useful vehicle for exploration and investigation. We also used this platform to build seven demonstrations of Air+Touch interactions (Figures 2 and 6-12), which span our outlined design space and demonstrate the viability of our approach. 

因此，为了探索可能实现的各种Air+Touch交互，我们需要构建我们自己的原型。虽然体积庞大，但我们的原型仅用作探索和调查。我们还使用该平台构建了七个Air+Touch交互演示应用（图2和图6-12），这些演示涵盖了Air+Touch的设计空间并展示了我们方法的可行性。

Hardware

Our prototype finger tracking system consists of a commercial smart phone and a PMD Camboard Nano [19] depth camera obliquely mounted to a common chassis (Figure 3). The Camboard Nano has a 90º×68º field of view and senses a 160×120px depth and infrared image from 5 to 50 cm at up to 90 fps. Finger tracking is performed on an external PC, and finger positions are sent to a mobile client via a wireless network. This setup allowed us to rapidly prototype ideas without having to instrument any customized hardware into the smart phone. 

我们的原型手指跟踪系统包括商用智能手机和倾斜安装在普通机箱上的PMD Camboard Nano [19]深度摄像头（图3）。 Camboard Nano具有90º×68º的视野，感应160×120px的深度和5至50厘米的红外图像，最高可达90 fps。手指跟踪在外部PC上执行，手指位置通过无线网络发送到移动客户端。这种设置使我们能够快速制作创意原型，而无需在智能手机中安装任何定制硬件。

Finger Tracking

Our finger-tracking software is written in C++ and uses the OpenCV library. Since the geometry of the phone is known, we can perform simple volume-based background subtraction (Figure 4b). We also remove noise due to infrared reflection from the phone’s screen (Figure 4c). Using this image, we identify the largest blob in the scene and perform contour analysis. We assume the fingertip to be the farthest contour point from the blob centroid (Figure 4d). To help reject false positives, we only look at contours situated along the fingers’ major orientation.

我们的手指跟踪软件使用C ++编写，并使用OpenCV库。由于手机的几何结构已知，我们可以通过简单的基于体积的背景减法（图4b）。我们还消除了手机屏幕红外反射引起的噪音（图4c）。使用此图像，我们识别场景中的最大斑点并进行轮廓分析。我们假设指尖是blob质心最远的轮廓点（图4d）。为了防止误报，我们只查看沿着手指主要方向的轮廓。

In cases when the finger is pointing towards the depth camera, the fingertip will not lie along a contour, but will rather lie inside the finger boundary. We detect this case by using our camera’s infrared image; due to skin’s high infrared reflectance (and the infrared emitter our depth camera employs), the fingertip will appear as a bright, roughly Gaussian spot. In this instance, we use the brightest spot as the fingertip position. 


在手指指向深度相机的情况下，指尖不会沿着轮廓，而是位于手指边界内。我们使用相机的红外图像检测到这种情况;由于皮肤的高红外反射率（以及我们的深度相机使用的红外发射器），指尖将显示为明亮的粗糙高斯光斑。在这种情况下，我们使用最亮点作为指尖位置。

This process yields a camera-space, fingertip X/Y/Z position representing the point of interest during an Air+Touch gesture. We then transform this raw 3D coordinate to X/Y screen coordinates (in pixels), along with a Z value (distance perpendicular from the screen). This transformation matrix is computed using three known points on the phone’s screen, selected in 3D camera space during a onetime calibration procedure (Figure 4, hollow dots). Finally, fingertip position is lightly smoothed with an exponentially weighted moving average. 

这个过程产生一个相机空间，指尖X/Y/Z位置，表示Air+Touch手势期间的兴趣点。然后，我们将此原始3D坐标转换为X/Y屏幕坐标（以像素为单位），以及Z值（垂直于屏幕的距离）。该变换矩阵使用手机屏幕上的三个已知点计算，在一次校准过程中在3D相机空间中选择（图4，空心点）。最后，使用指数加权移动平均对指尖位置进行平滑。

In-Air Gesture Classification

Our system records 3D finger position at 20 frames per second and maintains a positional history of approximately one second. When a touch down event occurs, we run the \$1 gesture recognizer [26] on the X and Y coordinates (as projected onto screen space) of the buffered finger positions.
If a good shape match is found with sufficient size, a corresponding interactive event is fired. For in-air gestures after touch, we run the recognizer on the buffer after approximately one second following the touch up event. In the touch-down case, we also check to see if a reciprocal touch
event happened within the last one second, and if so, interpret this as an in-air gesture being performed between two touch events.

我们的系统以每秒20帧的速度记录3D手指位置，并保持大约一秒的位置历史记录。当发生触碰事件时，我们在缓冲手指位置的X和Y坐标（投影到屏幕空间上）上运行 \$ 1手势识别器[26]。
如果找到具有足够大小的良好形状匹配，则触发相应的交互事件。对于触摸后的空中手势，我们在触摸事件后大约一秒钟后在缓冲器上运行识别器。在触摸时，我们还会检查过去一秒内是否有触摸时间，如果是，则将其解释为在两个触摸事件之间执行的空中手势。

To support in-air gestures that utilize Z distance (and not shape), we use a virtual plane situated 4cm above the screen as a threshold, providing something akin to a 3D crossing gesture. Each time this plane is crossed, a timestamp is recorded. If a touch event occurred within ±500ms, an interactive event is fired.

为了支持利用Z距离（而不是形状）的空中手势，我们使用位于屏幕上方4cm处的虚拟平面作为阈值，类似于3D交叉手势。每次越过该平面时，都会记录时间戳。如果触摸事件发生在±500ms内，则会触发交互事件。

EXAMPLE AIR+TOUCH INTERACTIONS TECHNIQUES
Based on our design findings from the observational study, we developed a set of example Air+Touch interactions (Figure 5). To provide a use context for these interaction techniques, we created four host applications: photo viewer, drawing app, document reader, and map. Please also see our Video Figure. 

基于我们观察研究的结果，我们开发了一组Air+Touch示例交互（图5）。为了提供这些交互技术的使用场景，我们创建了四个应用程序：照片查看器，绘图应用程序，文档阅读器和地图。另请参阅我们的视频图。

Air Before Touch
Unlike a mouse, touch (generally) only has one ‘button’. This has led to a persistent need for additional modal mechanisms, such as touch-and-hold to invoke e.g., a context menu. Toolbars are also popular, but consume valuable screen real estate. To mitigate this problem, Air+Touch allows users to perform in-air gestures before or en route to touching the screen, as a way to parameterize the touch event. We offer two example interactions for this technique.


与鼠标不同，触摸（通常）只有一个“按钮”。这导致了额外的模态机制的需求，例如触摸并保持以调用例如上下文菜单。工具栏也是一个常用场景，但却占用了宝贵的屏幕空间。为了缓解这个问题，Air+Touch允许用户在触摸屏幕之前或途中执行空中手势，作为参数化触摸事件的方式。我们为此技术提供了两个示例交互。

Circle-in-Air and Tap

In our photo viewer application (Figure 6), a user can trigger an image’s context menu by performing an in-air circling motion (Figure 6a-c) immediately before tapping on a desired image (Figure 6d-e). The in-air gesture specifies the command (in this case, trigger context menu), while the touch specifies the item of interest (e.g., a photo). These two motions are combined into a single, fluid finger motion: circle-and-tap. 

在我们的照片查看器应用程序（图6）中，用户可以通过在点击所需图像之前执行空中盘旋运动（图6a-c）来触发图像的上下文菜单（图6d-e）。空中手势指定命令（在这种情况下，触发上下文菜单），而触摸指定感兴趣的项目（例如，照片）。这两个动作组合成一个流畅的手指动作：盘旋触碰。

High-up and Tap for Mode Switching

One-handed map navigation is difficult on a mobile handheld device when only the thumb is available for interaction. Our map application demonstrates how Air+Touch allows users to switch between panning and zooming modes simply by raising the thumb ‘high-up’ before a tap (Figure 7). The person can then scroll on the screen to pan the map (Figure 7ab), or to zoom in/out of it as if using a
virtual slider (Figure 7cd). 

当只有拇指可用于交互时，单手地图导航在移动手持设备上是困难的。我们的地图应用程序演示了Air + Touch如何让用户在点击和缩放模式之间切换，只需在点击之前将拇指“抬高”（图7）即可。然后，该人可以在屏幕上滚动以平移地图（图7ab），或者放大/缩小地图，就像使用虚拟滑块（图7cd）。

Air Between Touch

Performing an in-air gesture in between consecutive touch events offers the opportunity to parameterize two-point or even multi-point actions.

在连续触摸事件之间执行空中手势提供了参数化两点或甚至多点动作的可能。

Finger ‘High Jump’ Between Touches to Select Text

Because there is no immediate way to disambiguate between scrolling and selection in touch interfaces, routine actions such as copy and paste are unwieldy. Air+Touch can streamline this process with a solution that takes two taps (Figure 8). A user can select a region of text by 1) tapping the beginning of the desired selected region, 2) raising the finger up high, and then 3) touching the end of the selected region. In sequence, these three steps can be executed in a single finger movement. Further touches can provide fine-grained adjustment if needed (d). This creates a gestural shortcut that chunks [4] the specification of text area and the intention to select it into a single finger ‘high-jump’.


由于没有直接的方法来消除触摸界面中滚动和选择之间的歧义，所以诸如复制和粘贴之类的常规操作是不实用的。 Air + Touch可以通过一个两步的方案简化这一过程（图8）。用户可以通过以下步骤选择文本区域：1）轻敲所需选定区域的开头，2）将手指抬高，然后3）触摸所选区域的末端。按顺序，这三个步骤可以在单个手指运动中执行。如果需要，进一步的接触可以提供细粒度的调整（d）。这创建了一个手势快捷方式，将文本区域的规范和选择它的意图分成[4]单手指'high-jump'。

Drawing an ‘L’ Between Touches for Marquee-Selection

Similarly, cropping or selecting a sub-region of an image typically requires first interrupting the current interaction and then specifying a special application mode (e.g., through toolbar buttons). However, with Air+Touch, this can be achieved in a more fluid manner, by performing an ‘L’ gesture in-between two touches. The first and second touches specify the opposite corners of a rectangular marquee. In piloting, we found that drawing an ‘L’ was a succinct and natural way of expressing the intention of selecting a rectangular area. 

类似地，裁剪或选择图像的子区域通常需要首先中断当前交互，然后指定特殊应用模式（例如，通过工具栏按钮）。然而，使用Air + Touch，这可以通过在两次触摸之间执行“L”手势以更流畅的方式实现。第一和第二触摸指定矩形选框的相对角。在驾驶中，我们发现绘制“L”是表达选择矩形区域意图的简洁而自然的方式。

Air After Touch

In this category, a person performs in-air gesture as the fingers leave the surface. Air augments touch by mapping touch to a specific function (similar to air before touch) or by allowing touch to continue the interaction unconstrained by screen size, e.g., clutch-free scrolling and zooming.

在该类别中，当手指离开表面时，人进行空中手势。空气通过将触摸映射到特定功能（类似于触摸前的空气）或通过允许触摸继续不受屏幕尺寸限制的交互（例如，无离合器滚动和缩放）来增强触摸。

Drawing a ‘Pigtail’ After Touch for Free-form Selection

In our drawing application, dragging a finger on the screen is used to draw. However, this path can be parameterized with a post-touch, in-air gesture. For example, by lifting the finger and performing a pigtail motion in the air (Figure 10), the last drawn path is converted into a clipped region that can be e.g., moved, scaled or copied to the clipboard.

在我们的绘图应用程序中，在屏幕上拖动手指用于绘制。但是，可以使用触摸后空中手势来参数化此路径。例如，通过抬起手指并在空中进行尾纤运动（图10），最后绘制的路径被转换成可以例如移动，缩放或复制到剪贴板的裁剪区域。

Cycling In-Air After Touch to Zoom on a Map

We previously described an air before touch technique that enables quick mode switching between pan and zoom. Another solution is to ‘divide the labor’ – touch can be used to pan, while in-air cycling zooms. More specifically, a person starts by tapping on e.g., a map to specify the zoom center (a). As she releases her finger from the screen, a ‘zoom mode’ may be triggered by drawing
a circle high in the air (Figure 11b). Once in ‘zoom mode’, continuously cycling the finger in the air zooms in or out (depending on cyclical direction) at the tapped location (Figure 11cde). Tapping on the screen, or a short period of non-cyclical finger motion exits the zoom mode. This technique leverages the concept of a repeated gesture; even if the finger accidentally draws a circle in-air after touch, it will at worst turn on the zooming mode but not cause any actual zooming.

我们之前描述过触摸前手势技术，可以在平移和缩放之间快速切换模式。另一种解决方案是“分工” - 触摸可用于平移，而空中环绕用于缩放。更具体地，一个人通过点击例如地图来开始以指定缩放中心（a）。当她从屏幕上松开手指时，可以通过高空中画圈触发“缩放模式”（图11b）。一旦处于“缩放模式”，手指在空中连续旋转用于放大或缩小（取决于旋转方向方向）（图11cde）。点击屏幕或短时间的非环形动作会退出缩放模式。这种技术利用了重复手势的概念;即使手指在触摸后意外地在空中画圆，也会在最坏的情况下打开变焦模式但不会导致任何实际的缩放。

Hovering After Touch to Change Scroll Speed

On a touch screen, clutching is inevitable as touch is constrained by the screen’s physical surface. For example, scrolling through a long page requires repetitive finger flicking [20, 21]. Our reader application enables fine control of page scrolling for long lists. When a user triggers
inertial scrolling via a flick (a), he can use the hover height of the finger to control the scrolling speed – higher finger position maps to faster scrolling (Figure 12b-d). This is similar to Zliding and Zoofing techniques [20, 21], but uses Z-distance instead of pressure. Touching the screen stops scrolling. Two height thresholds are used to differentiate this ‘hover scroll’ from a normal scrolling, which is unaffected. 

在触摸屏上，由于触摸受到屏幕物理表面的限制，因此不可避免地会发生“clutching”。例如，滚动长页面需要重复手指摆动[20,21]。我们的阅读器应用程序可以精确控制长列表的页面滚动。当用户触发时
通过摆动控制（a）惯性滚动，他可以使用手指的悬停高度来控制滚动速度 - 更高的手指位置映射到更快的滚动（图12b-d）。这类似于Zliding和Zoofing技术[20,21]，但使用Z距离代替压力。触摸屏幕停止滚动。两个高度阈值用于区分这种“悬停滚动”与正常滚动，这不受影响。

DISCUSSION
The example techniques we have presented above are only a small subset of the possible interactions, yet we believe demonstrate the expressiveness and promise of Air+Touch. Importantly, Air+Touch actions can work in concert with conventional touch gestures, such as one finger pan and
click, pinch to zoom, and various chorded swipes. As highlighted by our observational study and implemented in our example applications, Air+Touch techniques can weave inair gestures before, between, and after touch events. Through extensive use and piloting, it become apparent that
these categorization have different strengths and can support a variety of interactive tasks: 

 Both air before and after touch enable quick mode switching connected to a touch down/up (e.g., Figure 6). They can also specify an action specific to a set of touchpoints (e.g., Figure 10);
 Air after touch further allows a user to continue a touchinitiated operation with in-air, continuous motions (e.g., Figure 11);
 Air between touches is good for tasks that by nature require specifying multiple screen positions. An air-gesture command can be embedded in between the touch events, saving the overhead of tool or mode switching (e.g., Figure9). 

Chunking Air and Touch into Fluid Interactions

Table 1 provides a comparison of how Air+Touch techniques approach the design for six interactive tasks in comparison with existing touch-only interaction. While the elements of these tasks remain the same (e.g., text selection consists of specifying the selection mode and the region to select), a touch-only design presents them as discrete steps. Air+Touch, however, chunks these elements into fluid interactions [4]. For expert users, Air+Touch could become integrated into their interactions as a single flow of movement, whereas touch-only actions are inherently sequential.

Choosing Air Gestures based on Accompanying Touch
Our initial concept to trigger a context menu (Figure 6e) was by drawing a ‘pigtail’ and tapping on an target (similar to [8]’s design). However, we found it difficult to perform, because as the finger drew the ‘pigtail’, it strayed from its original target, requiring the user to retarget at the end of the gesture. In contrast, a full ‘circle’ gesture was easier, as the finger could complete a full loop, naturally returning to its starting point, from which the user could simply tap down onto the target. Conversely, when designing aftertouch in-air gestures, we found that ‘pigtails’ became easyto perform, as there was no ending targeting constraint. This suggests that the choice of in-air gesture should consider whether it affects the touch that precedes or follows it.

Segmenting Air Gestures Before and After Touch
For air before and after touch, touches only segment air’s start or end points, leaving the developer to decide when to start/stop processing the finger’s remaining movement. This translates to the implementation level question of setting the size of the buffer that keeps a history of the finger’s 3D positions. In prototyping, we visualized the finger’s trajectory as a projection onto the screen. We chose buffer sizes that neither gave an incomplete gesture (too few points), nor overshot it (too many points). An alternate approach would be to analyze different buffer sizes, choosing gestures that yield highest recognition confidences.

CONCLUSION
The prevalence of hover technologies at CES 2014 and the continued inclusion of hover in flagship devices (such as the soon-to-be-released Galaxy S5) suggests in-air technologies will continue to mature and could play an increased role in touch devices. Today, a scant few ‘air’ gestures are supported and are fundamentally compartmentalized from touch interactions. Our work helps point the way to more powerful interactions, by synergistically interweaving touch and air modalities, where air augments touch, adding expressivity, and touch segments in-air gestures to resolve segmentation ambiguity. With good design, these actions can blend into single, fluid movements, offering a level of expressivity rarely achieved by each modality in isolation. Nonetheless, there is much future work to consider, including expanding the gesture vocabulary, capturing not just 3DOF position, but also 3DOF rotation of the fingers, as well as utilizing several fingers at once. 