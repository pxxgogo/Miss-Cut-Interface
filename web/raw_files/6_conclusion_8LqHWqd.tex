\chapter{结论与展望}

智能手机全手型交互是一种全新的交互理念，它希望通过捕捉用户操作智能手机时的手部图像，实现对用户交互行为的全感知。

在本论文中，我们基于全手型交互理念，提出了一套高效的在RGB与IR两种模态下的基于单目图像的智能手机手部感知的算法，该算法能实现握姿检测、双模态下的指尖检测、指尖运动模式检测功能，并输出握姿、指尖、运动模式等手部抽象语义信息。

我们通过MobileNetV2模型实现鲁棒的握姿分类，通过MobileNetV2-SSD模型实现RGB图像的指尖检测。在IR环境下，我们提出了一种高效的基于握姿与边缘曲率统计特征的轮廓分类与指尖识别方法。基于检出的指尖信息，我们提出了指尖运动模式检测算法，能够检测指尖是否处于下落状态。基于以上算法流程，我们实现了误触检测与免验证检测两个创新性的交互应用，并通过定量实验与用户实验对其进行了分析。

在未来的工作中，我们将会针对以下三点继续进行深入的研究：

\begin{itemize}
    \item 探索以全手交互为目标的硬件上的更多可能性。例如，通过广角鱼眼镜头捕捉180度空间内的更丰富的图像信息；
    \item 尝试引入更丰富的交互信息，例如，在180度广角摄像头下进行人脸信息、身体运动信息的检测，并将它们与手部信息整合，达到更强的感知效果；
    \item 继续探索全手交互场景下更多有价值的交互应用。
\end{itemize}


