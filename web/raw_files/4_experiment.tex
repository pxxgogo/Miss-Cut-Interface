\chapter{实验设计}

在本章，我们构建了RGB与IR的握姿分类与指尖检测数据集，并在此数据集的基础上对本论文提出的方法的效率与准确率进行了评估。除此之外，我们还针对误触检测与hand-around检测设计了一系列用户实验，研究用户对两种应用的接受程度与主观评价，以及应用对于效率的提升。

\section{数据集}

\textbf{RGB数据集：}我们收集了10位实验者的7种不同握姿的RGB图像数据，7种不同握姿包括：左手单手操作、右手单手操作、左手持握右手操作、右手持握左手操作、双手拇指操作、左手横向持握、右手横向持握。每位实验者要求使用每种握姿操作手机，并录制一分钟的视频，视频分辨率为$640 \times 480$，帧率为30fps，每种握姿共产生$10 \times 60 \times 30=18000$视频帧，总共可获得126000帧带握姿分类标签的图像数据。对于握姿分类任务，我们将数据集按照8名实验者/1名实验者/1名实验者的方式划分训练、验证与测试数据集。对于指尖检测任务，我们随机从前五种握姿中抽取1000帧图像，对这1000帧图像进行人工的指尖标注，每张图中标注出所有的指尖候选框，并为候选框进行四分类（持握手拇指、持握手其他手指、操作手拇指、操作手其他手指）。标注数据以COCO数据集格式存储。

\textbf{IR数据集：}我们收集了2位实验者的5种不同握姿的RGB图像数据，5种不同握姿包括：左手单手操作、右手单手操作、左手持握右手操作、右手持握左手操作、双手拇指操作。实验者在完全黑暗的环境下使用每种握姿操作手机，并录制一分钟的视频，视频分辨率为$640 \times 480$，帧率为30fps，每种握姿共产生$2 \times 60 \times 30=3600$视频帧，总共可获得7600帧带握姿分类标签的图像数据。对于握姿分类任务，我们将数据集按照1名实验者/1名实验者的方式划分训练与测试数据集。对于指尖检测任务，我们随机抽取100帧图像，对这100帧图像进行轮廓标注（左持握手拇指、右持握手拇指、双手拇指、持握手四指、操作手、其他）与指尖标注（在轮廓上）作为轮廓模板与指尖模板。

\section{算法评测}
在这一节，我们将基于我们构建的数据集，对本论文提出的握姿分类、指尖检测、指尖下降检测方法的效率与准确率进行评估。



对于握姿分类，我们在带类别标注的RGB数据集上（5类与7类），分别使用在ImageNet上预训练的MobileNetV2网络进行finetune训练，使用Tensorboard记录训练步骤的损失与每个epoch验证集的准确率。
除此之外，我们还使用了DenseNet161、ResNet152和SqueezeNet1.1进行了相同的测试，并横向比较了不同网络结构在检测性能上的差异。

对于RGB指尖识别，我们使用上述带指尖标注的COCO格式RGB图像数据训练MobileNetV2-SSD网络，使用Tensorboard记录训练步骤的分类损失、位置损失、正则损失及困难样本数目，
以及每个epoch验证集上的平均准确率均值（mAP）与平均召回率（AR），并对实验结果进行分析与更细致的讨论。

对于IR指尖识别，我们在IR数据集上运行我们的指尖检测算法，在生成的实验结果中随机抽取100帧进行人工标注，标注的内容包括实际的指尖数目、检出的指尖数目、正确检出的指尖数目，并进行分析。

对于误触识别中的下降检测，我们首先在IR数据集上运行指尖下降检测算法，我们从所有视频中选取三个最有代表性的视频：单手拇指操作、双手拇指操作、单手持握另一只手操作。这三个视频涵盖了用户日常操作手机的大部分握姿与手势。我们在每个视频中随机选取100-150个0.5s的视频区间，人工标注该区间下降检测结果与实际行为是否一致。



对于误触识别中的触点分类，我们分两类情况进行评测。第一类的评测数据集均采自真实误触场景，用于模拟手部边缘误触的情况：实验者依次点击屏幕上绿色的小球进行消除，在整个过程中，屏幕上所有触点将会被记录，我们将绿色的小球的坐标标记为非误触点，其他触点坐标标记为误触点，每组数据由一个正确的触点、一个同一时刻产生的误触点和该时刻的手部图像构成。第二类的评测数据集来自正确的触点与随机生成的误触点（与正确触点距离大于一定值），用于模拟屏幕上有其他干扰信号的情况，每组数据由一个触点（正确触点或错误触点）和该时刻的手部图像构成。评测任务是，在上述两种情况中，对于第一种，区分哪个触点是正确触点；对于第二种，区分改触点是否为正确触点。

对于Hand-Around检测，我们在RGB数据集上进行Hand-On/Hand-Around/Hand-Off三分类与Hand-On/Hand-Off两分类的评测，分别测量每种情况的分类正确率。所有的模型与实验设定同握姿分类，前馈特征提取模型采用MobileNetV2，训练集/测试集按照1名实验者/1名实验者划分。

\section{用户实验}

在这一节，我们主要针对误触检测与Hand-Around不熄屏两个被动交互应用，从用户的角度出发，对问题发生频率、用户体验影响、用户效率影响、解决方案的价值这四个维度进行评价。我们希望通过用户实验来获取用户对于误触检测与Hand-Around检测的主观反馈。

我们通过问卷对20名实验参与者（12男8女，年龄20-30，拥有大于5年的电容屏智能手机使用经历）进行调查。

针对误触问题，我们列举了7种日常生活中使用手机时会出现误触的场景，它们覆盖了方法中描述的三类误触问题（如表\ref{MistouchTable}）。对于每一种误触场景，我们请参与者就发生频率（参考：7分 每天＞10次，6分 每天5-10次，5分 每天1-5次，4分 每周1-5次，3分 每月1-5次，2分 每年1-10次，1分 从来没发生过）、体验影响（参考：7分 影响很大，1分 几乎无影响）、效率影响（参考：7分 影响很大，1分 几乎无影响）进行7分Likert量评分，其中每种评分对应一个程度相关的陈述；紧接着，我们向他们描述针对该误触场景的解决方案所能达到的理想效果，请他们用7分Likert量评价该解决方案的价值（或者说对他们体验/效率的提升程度，或者他们是否想要这样的技术/体验）。

\begin{table}[htbp]

\centering
\caption{常见的智能手机误触场景}
\label{MistouchTable}
\begin{tabular}{p{40 pt}p{280 pt}}
 \toprule
序号 & 场景 \\
 \midrule
1 & 单手使用手机时发生边缘误触 \\
2 & 单手使用手机时去“够”屏幕上够不着位置时发生的误触 \\
3 & 手机放在口袋中发生误触 \\
4 & 湿着手使用手机时操作不灵敏或误触 \\
5 & 下雨的时候在室外使用手机时操作不灵敏或误触 \\
6 & 手机息屏时握着手机不小心把屏幕点亮 \\
7 & 看视频时手不小心碰到手机弹出菜单 \\
\bottomrule
 \end{tabular}\\[2pt]
\end{table}

紧接着，我们邀请其中的5位参与者在实验设备上进行小球消除的任务：屏幕上的不同位置会依次出现绿色的小球，当参与者点中当前小球的位置时会出现下一个新的小球，在误触模式下，只有在无误触前提下点击才有效，若发生误触，则会出现一个弹框，参与者需要将其点击消除才能继续完成后续任务；在误触消除模式下，若有多个触点，则误触算法会自动抑制误触触点。参与者需要进行一次误触模式的任务与一次误触消除模式的任务，需要在规定的时间（2min）内完成尽可能多次的点击，他们的点击次数、误触次数以及两次任务的主观愉悦度（1-7分）将被记录。

\begin{table}[htbp]
\centering
\caption{Hand-Around观点}
\label{HandAroundOp}
\begin{tabular}{p{40 pt}p{200 pt}}
 \toprule
序号 & 观点 \\
 \midrule
1 & 我愿意使用这种技术 \\
2 & 我担心这种技术的安全性 \\
3 & 我觉得这种技术能提高我的效率 \\
4 & 我觉得这种技术能带给我更好的体验 \\
5 & 这种技术在指纹解锁的场景下很有用 \\
6 & 这种技术在脸部解锁的场景下很有用 \\
7 & 这种技术在虹膜解锁的场景下很有用 \\
8 & 这种技术在密码解锁的场景下很有用 \\
\bottomrule
 \end{tabular}\\[2pt]
\end{table}

针对hand-around不锁定应用，我们首先调查参与者的日常生活中的手机解锁频率、手机解锁方式、以及他们对当前手机认证方式效率的评价。然后我们向用户展示了8种关于解锁场景、解锁效率以及Hand-Around应用的观点，请他们用7分Likert量表示对该观点的认同程度，观点如表\ref{HandAroundOp}。除此之外，我们还调研了用户对于Hand-Around感应（即手部靠近手机时手机显示一些信息）的交互想法的接受度，以及询问他们愿意以Hand-Around感应的形式获取哪些信息。

